{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Practising Movie Reviews Sentiment Analysis\n",
    "    \n",
    "    Testing with git\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./aclImdb_v1/aclImdb/test/neg/10000_4.txt')\n",
    "f = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well. Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal. Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film? And why the heck does he always play the exact same character? From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying...<br /><br />Overall, this is second-rate action trash. There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script. The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite. 4/10.\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import unicodecsv as csv\n",
    "import unicodedata as un\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "in_path = './aclImdb_v1/aclImdb/train/'\n",
    "out_path= './aclImdb_v1/aclImdb/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files processed:  25001\n",
      "Number of files error:  0\n",
      "Time taken in seconds: 93.6330451965332\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "error_counter = 0\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "label = 0\n",
    "\n",
    "# Prepare dictionary of necessary unicode\n",
    "# Thanks to https://stackoverflow.com/a/11066687/4595807\n",
    "# We want to protect '-'\n",
    "# HYPHEN-MINUS = UNICODE DECIMAL VALUE = 45\n",
    "table = dict.fromkeys(i for i in range(sys.maxunicode) \n",
    "                        if un.category(chr(i)).startswith(('P','N','S','Cf','Cn','Cc')))\n",
    "#                         and not un.category(chr(i)).startswith('Pd'))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "with open(out_path, 'wb') as out_file:\n",
    "    writer = csv.writer(out_file, encoding='utf-8')\n",
    "\n",
    "    header = (\"label\", \"data\")\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for root, dirs, files in os.walk(in_path, topdown=True):\n",
    "        for name in files:\n",
    "            curr_file = os.path.join(root, name)\n",
    "#            print(curr_file)\n",
    "            try:\n",
    "                # Read current file and remove BOM and newline characters\n",
    "                # uf03c and uf03c are invalid unicode characters and don't have any category\n",
    "                # so had to remove manually\n",
    "                fp = open(curr_file, encoding='utf-8-sig').read()\n",
    "                fp = fp.replace('<br />', '')\n",
    "                fp = fp.translate(table)\n",
    "                fp = fp.lower()\n",
    "                \n",
    "                #tokenize the word\n",
    "               # fp = word_tokenize(fp)\n",
    "                #fp = [w for w in fp if not w in stop_words]\n",
    "              #  print(fp)\n",
    "                \n",
    "                \n",
    "                # Remove extra spaces and hyphens but does not remove that's between words आ-आफ्नो\n",
    "                # Conditional removal of HYPHEN-MINUS\n",
    "                # Looks for space before/after hyphen, if present remove it\n",
    "                #fp = re.sub(r\"(?<!\\w)[-]|[-](?!\\w)\",'',fp)\n",
    "                \n",
    "                # Normalize the unicode so that\n",
    "                # canonical-equivalent ones will also have precisely the same binary representation\n",
    "                final_msg = label, fp\n",
    "                \n",
    "                # Write into CSV file format - label, data\n",
    "                writer.writerow(final_msg)\n",
    "\n",
    "                # Counter setup to count file processed\n",
    "                counter = counter + 1\n",
    "#                 break\n",
    "                \n",
    "\n",
    "            except IOError as e:\n",
    "                print (\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "                error_counter = error_counter + 1\n",
    "#                 break\n",
    "                \n",
    "                \n",
    "        label += 1\n",
    "\n",
    "out_file.close()\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print('Number of files processed: ',counter)\n",
    "print('Number of files error: ',error_counter)\n",
    "\n",
    "print('Time taken in seconds:',(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ashish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('aclImdb_v1/aclImdb/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ashishashishvirtualbox filehomeashishconfiglib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i get tired of my  and  year old daughters con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this movie is outrageous funny ribald sophisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i have to start saying it has been a long time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>if the very thought of arthur askey twists you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               data\n",
       "0      0  ashishashishvirtualbox filehomeashishconfiglib...\n",
       "1      1  i get tired of my  and  year old daughters con...\n",
       "2      1  this movie is outrageous funny ribald sophisti...\n",
       "3      1  i have to start saying it has been a long time...\n",
       "4      1  if the very thought of arthur askey twists you..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('aclImdb_v1/aclImdb/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ok so it can be done we have here the perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i thought this was a very good movie someone s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>are we allowed to interfere with our fellowmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i described woody allens manhattan as perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>married to the mob was one of the first vhs ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               data\n",
       "0      1  ok so it can be done we have here the perfect ...\n",
       "1      1  i thought this was a very good movie someone s...\n",
       "2      1  are we allowed to interfere with our fellowmen...\n",
       "3      1  i described woody allens manhattan as perfect ...\n",
       "4      1  married to the mob was one of the first vhs ta..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in Train =  31408174\n",
      "Tokens in Test =  30660597\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "counter1 = 0\n",
    "for each_row in df_train['data']:\n",
    "    counter += len(each_row)\n",
    "\n",
    "for each_row in df_test['data']:\n",
    "    counter1 += len(each_row)\n",
    "print(\"Tokens in Train = \",counter)\n",
    "print(\"Tokens in Test = \", counter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Tokens in Train in each sentence=  1256.2767089316428\n",
      "Average Tokens in Test in seach sentence =  1226.42388\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Tokens in Train in each sentence= \",counter/df_train.shape[0])\n",
    "print(\"Average Tokens in Test in seach sentence = \", counter1/df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "tokens_list_train = df_train.data.tolist()\n",
    "tokens_list_test = df_train.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for i in tokens_list_train:\n",
    "    for j in i.split():\n",
    "        tokens.append(j)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filehomeashishconfiglibreoffice',\n",
       " 'i',\n",
       " 'get',\n",
       " 'tired',\n",
       " 'of',\n",
       " 'my',\n",
       " 'and',\n",
       " 'year',\n",
       " 'old']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list_test[3].split()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('one', 'of', 'the'), 4815),\n",
       " (('this', 'movie', 'is'), 2476),\n",
       " (('of', 'the', 'film'), 2363),\n",
       " (('a', 'lot', 'of'), 2255),\n",
       " (('this', 'is', 'a'), 2140),\n",
       " (('of', 'the', 'movie'), 2039),\n",
       " (('some', 'of', 'the'), 1855),\n",
       " (('is', 'one', 'of'), 1746),\n",
       " (('the', 'film', 'is'), 1686),\n",
       " (('this', 'film', 'is'), 1669)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram = ngrams(tokens,3)\n",
    "\n",
    "Counter(trigram).most_common(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
